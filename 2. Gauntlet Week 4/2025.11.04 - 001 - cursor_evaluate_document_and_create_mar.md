# Evaluate document and create markdown file
_Exported on 11/4/2025 at 19:35:46 CST from Cursor (1.7.54)_

---

**User**

evaluate @[PLAT]-Nerdy Case 5_ 48-Hour AI Product Sprint.pdf and generate a md file that is exactly the same content

---

**Cursor**


Extracting text from the PDF and generating a markdown file with the same content. Creating a script to extract the text:


Creating a Python script to extract the PDF content:


```python
#!/usr/bin/env python3
"""Extract text from PDF and convert to markdown."""

import sys
import os

try:
    import PyPDF2
    
    def extract_pdf_text(pdf_path):
        """Extract text from PDF file."""
        with open(pdf_path, 'rb') as pdf_file:
            reader = PyPDF2.PdfReader(pdf_file)
            text_content = []
            for page in reader.pages:
                text = page.extract_text()
                if text.strip():
                    text_content.append(text)
            return '\n\n'.join(text_content)
except ImportError:
    try:
        import pdfplumber
        
        def extract_pdf_text(pdf_path):
            """Extract text from PDF file using pdfplumber."""
            text_content = []
            with pdfplumber.open(pdf_path) as pdf:
                for page in pdf.pages:
                    text = page.extract_text()
                    if text:
                        text_content.append(text)
            return '\n\n'.join(text_content)
    except ImportError:
        print("Error: Neither PyPDF2 nor pdfplumber is installed.")
        print("Please install one: pip install PyPDF2 OR pip install pdfplumber")
        sys.exit(1)

if __name__ == "__main__":
    pdf_path = r"2. Gauntlet Week 4\1. Artifacts\1. Requirements\PDFs\[PLAT]-Nerdy Case 5_ 48-Hour AI Product Sprint.pdf"
    
    if not os.path.exists(pdf_path):
        print(f"Error: PDF file not found at {pdf_path}")
        sys.exit(1)
    
    try:
        text = extract_pdf_text(pdf_path)
        print(text)
    except Exception as e:
        print(f"Error extracting PDF: {e}")
        sys.exit(1)

```

Creating a properly formatted markdown file from the extracted content:


```markdown
# Nerdy Case 5: 48-Hour AI Product Sprint

## The Challenge:

Choose **ONE** of these urgent Nerdy problems and build a complete solution using AI-first development in 48 hours:

### Option A: AI Study Companion

Build a persistent AI companion that lives between tutoring sessions, remembers previous lessons, assigns adaptive practice, answers questions conversationally, and drives students back to human tutors when needed.

Must integrate with existing session recordings and generate measurable learning improvements.

#### Retention Enhancement Requirements:

- When student completes goal → must suggest related subjects (address 52% "goal achieved" churn)
- SAT complete → surface college essays, study skills, AP prep
- Chemistry → suggest physics, STEM subjects
- Nudge students who have <3 sessions by Day 7 to book next session
- Show multi-goal progress tracking (not just single subject)

### Option B: Tutor Quality Scoring System

Create an automated system that evaluates tutor performance across every session, identifies coaching opportunities, predicts which tutors will churn, and recommends interventions.

The system must process 3,000 daily sessions and provide actionable insights within 1 hour of session completion.

#### Retention Enhancement Requirements:

- Detect patterns leading to poor first session experiences (24% of churners fail here)
- Flag tutors with high rescheduling rates (98.2% of reschedules are tutor-initiated)
- Identify tutors at risk of no-shows (16% of tutor replacements due to no-shows)

### Option C: Intelligent Operations Dashboard

Build a real-time command center that monitors marketplace health, predicts supply/demand imbalances, automatically adjusts tutor recruiting campaigns, and alerts operators to anomalies.

Must handle 50+ data streams and provide explainable AI recommendations.

#### Retention Enhancement Requirements:

- Customer health score dashboard showing:
  - First session success rates by tutor/subject
  - Session velocity trends by cohort
  - IB call spike alerts (≥2 calls in 14 days = churn risk)
  - Churn prediction by customer segment
  - Instant tutor supply vs. demand predictions
  - Early warning alerts for at-risk customers

## Sprint Requirements:

- **First 24 hours:** Use only AI coding assistants (no manual coding)
- **Hour 24-36:** Refine and debug with mixed approach
- **Hour 36-48:** Production hardening and documentation
- Must include working demo, not just designs
- Solution must integrate with existing Rails/React platform

## Deliverables:

- Working prototype deployed to cloud (AWS or Vercel)
- Documentation of AI tools used and prompting strategies
- 5-minute demo video showing actual functionality
- Cost analysis for production deployment
- 90-day roadmap for full implementation

## Success Metrics:

- Does it solve a real business problem?
- Could this ship to production within 2 weeks?
- Does it leverage AI in sophisticated ways?
- Clear path to ROI within 90 days?

```

Cleaning up the temporary script and verifying the markdown file:


Created a markdown file with the same content as the PDF. The file is saved at:

**`2. Gauntlet Week 4/1. Artifacts/1. Requirements/[PLAT]-Nerdy Case 5_ 48-Hour AI Product Sprint.md`**

The markdown includes:
- Title and main sections formatted as headers
- Three options (A, B, C) with their descriptions and requirements
- Sprint requirements
- Deliverables
- Success metrics

All content from the PDF has been preserved and formatted in markdown. The file is ready to use and matches the structure and content of the original PDF document.

---

**User**

Please review the chats in @c:\Users\grate\Documents\Cursor\1. CollabCanvas\1. Prior chats/ , @c:\Users\grate\Documents\Cursor\2. MessageAI\1. Prior Chats/ , and @c:\Users\grate\Documents\Cursor\3. ClipForge\1. Prior Chats/ along with @2025.10.16-PROJECT-SETUP-SUCCESS-PATH-SUMMARY.md . This will give you a solid idea of the form of our converations and expected relationship/artifacts for our project work.  Then, evaluate @[PLAT]-Nerdy Case 5_ 48-Hour AI Product Sprint.md nd provide a path to success for each in a individual markdown files - each should be a PRD that encompasses the entire project, with a phased approach and granular planning.  The projects are all due Sunday, November 9th, 2025.  Phase 1 of each project will be called the MVP (Minimum Viable Product) and must include all the basic functionality required for each project.  We will be using Integrated Unt Testing along the way, so include that as the final task for each phase, and anytime we add a layer of functionality.  The Phase 1 (MVP) is due Tuesday, November 4, 2025.  An 'Early Submission' is required on Friday, November 7, 2025.  For each of the 3 submissions required for each of the projects, w will be generating a demonstartion video to highlight the state of the project.  Include as the last Task in each phase for the due dates: generaating a Demo Video Script targetting a 3 minute video,and a Cue Card that includes just the narration of the Script and bulletized highlights covered by each narration line.  When requesting to run commands in the terminal, ALWAYS use Powershell syntax. When we begin executing the projects, NEVER proceed to the next task without my confirmation.

---

**Cursor**


Reviewing the reference chats and project setup summary to understand the format and expectations, then creating PRDs for each option.


Reviewing a sample chat to understand the format and structure:


Creating PRDs for each option. Starting with a TODO list, then creating the three PRDs:


Creating the three PRDs, starting with Option A: AI Study Companion:


```markdown
# Product Requirements Document: AI Study Companion

**Version:** 1.0  
**Date:** November 3, 2025  
**Project Duration:** 7 Days (Nov 3 - Nov 9, 2025)  
**Project Start:** November 3, 2025  
**Framework:** Based on October 16, 2025 success path methodology  
**Target:** Persistent AI companion for between-tutoring-session support

---

## Executive Summary

AI Study Companion is a persistent AI-powered learning assistant that lives between tutoring sessions, remembers previous lessons, assigns adaptive practice, answers questions conversationally, and drives students back to human tutors when needed. The system integrates with existing Nerdy session recordings and generates measurable learning improvements while addressing critical retention challenges.

**Key Deliverables:**
- ✅ Persistent AI companion with session memory
- ✅ Adaptive practice assignment system
- ✅ Conversational Q&A interface
- ✅ Multi-goal progress tracking
- ✅ Retention enhancement features (goal completion suggestions, session nudges)
- ✅ Integration with existing Rails/React platform
- ✅ Session recording analysis and extraction
- ✅ Measurable learning improvements tracking

**Success Targets:**
- **MVP (Nov 4)**: Core AI companion with memory, basic practice assignments, Q&A interface
- **Early Submission (Nov 7)**: + Retention features (goal suggestions, nudges), multi-goal tracking
- **Final Submission (Nov 9)**: + Session recording integration, analytics dashboard, comprehensive testing

**Business Impact:**
- Addresses 52% "goal achieved" churn through subject suggestions
- Reduces early churn by nudging students with <3 sessions by Day 7
- Improves engagement through persistent companion between sessions
- Generates measurable learning improvements

---

## Project Timeline

| Milestone | Date | Deliverable |
|-----------|------|-------------|
| **Phase 1: MVP** | Tuesday, November 4, 2025 | Core AI companion with memory, basic practice assignments, conversational Q&A |
| **Early Submission** | Friday, November 7, 2025 | + Retention features (goal suggestions, session nudges), multi-goal progress tracking |
| **Final Submission** | Sunday, November 9, 2025 | + Session recording integration, analytics dashboard, comprehensive testing, demo video |

---

## Technology Stack

### AI/ML Stack
- **LLM Provider**: OpenAI GPT-4 (or Claude 3.5 Sonnet) for conversational AI
- **Embeddings**: OpenAI text-embedding-3-small for semantic search
- **Vector Database**: PostgreSQL with pgvector extension (or Pinecone for production)
- **Session Memory**: LangChain ConversationBufferMemory + VectorStoreRetrieverMemory

### Backend Stack
- **Framework**: Ruby on Rails 7+ (integrates with existing platform)
- **API**: RESTful API + GraphQL for complex queries
- **Background Jobs**: Sidekiq for async processing (session analysis, practice generation)
- **Database**: PostgreSQL (existing Nerdy infrastructure)
- **Caching**: Redis for session state and practice caching

### Frontend Stack
- **Framework**: React 18+ (integrates with existing platform)
- **State Management**: React Query for server state, Zustand for client state
- **UI Components**: Existing Nerdy design system components
- **Real-time**: Action Cable (WebSocket) for live updates
- **Charts**: Recharts or Chart.js for progress visualization

### Integration Stack
- **Session Recordings**: Existing Nerdy API for session data
- **Authentication**: Existing Nerdy authentication system
- **File Processing**: ActiveStorage for session recording files
- **Audio Transcription**: OpenAI Whisper API (or existing transcription service)

### Development Tools
- **Testing**: RSpec (backend), Jest + React Testing Library (frontend)
- **Linting**: ESLint, RuboCop
- **Type Checking**: TypeScript for React, Sorbet for Ruby (optional)
- **Documentation**: JSDoc, YARD

---

## Architecture Overview

### System Components

```
ai-study-companion/
├── backend/
│   ├── app/
│   │   ├── models/
│   │   │   ├── student.rb
│   │   │   ├── study_session.rb
│   │   │   ├── ai_conversation.rb
│   │   │   ├── practice_assignment.rb
│   │   │   ├── learning_goal.rb
│   │   │   └── session_recording.rb
│   │   ├── controllers/
│   │   │   ├── api/
│   │   │   │   ├── ai_companion_controller.rb
│   │   │   │   ├── practice_assignments_controller.rb
│   │   │   │   └── progress_controller.rb
│   │   ├── services/
│   │   │   ├── ai/
│   │   │   │   ├── conversation_service.rb
│   │   │   │   ├── memory_service.rb
│   │   │   │   ├── practice_generator_service.rb
│   │   │   │   └── session_analyzer_service.rb
│   │   │   ├── retention/
│   │   │   │   ├── goal_suggestion_service.rb
│   │   │   │   └── nudge_service.rb
│   │   └── jobs/
│   │       ├── session_analysis_job.rb
│   │       └── practice_generation_job.rb
│   ├── db/
│   │   ├── migrate/
│   │   └── schema.rb
│   └── spec/
├── frontend/
│   ├── src/
│   │   ├── components/
│   │   │   ├── CompanionChat/
│   │   │   ├── PracticeAssignments/
│   │   │   ├── ProgressTracking/
│   │   │   └── RetentionFeatures/
│   │   ├── services/
│   │   │   ├── api.ts
│   │   │   └── websocket.ts
│   │   └── hooks/
│   │       ├── useCompanion.ts
│   │       └── usePractice.ts
│   └── __tests__/
└── docs/
    ├── ai-prompting-strategies.md
    └── integration-guide.md
```

### Data Flow

1. **Session Recording Flow**: Session ends → Recording uploaded → Transcription → Analysis → Memory storage
2. **Conversation Flow**: Student asks question → AI retrieves context from memory → Generates response → Stores conversation
3. **Practice Generation Flow**: Session analyzed → Learning gaps identified → Practice generated → Assigned to student
4. **Retention Flow**: Goal completed → Suggestion service triggered → Related subjects suggested → Nudge scheduled if needed

---

## Phase Breakdown

### Phase 1: MVP (Due Tuesday, November 4, 2025)

**Objective**: Core AI companion functionality working end-to-end

#### Phase 1.1: Project Setup & Foundation (120 minutes)

**Task 1.1.1**: Initialize Rails API backend
- Duration: 30 minutes
- Create new Rails API app or integrate with existing Nerdy platform
- Configure PostgreSQL database
- Setup basic API structure with versioning (api/v1/)
- Install dependencies: `gem 'openai', gem 'sidekiq', gem 'pgvector'`
- PowerShell: `rails new ai_study_companion --api --database=postgresql`

**Task 1.1.2**: Setup React frontend integration
- Duration: 30 minutes
- Create React components directory structure
- Setup React Query for API communication
- Configure WebSocket connection (Action Cable)
- Install dependencies: `npm install @tanstack/react-query axios`
- Create base API service client

**Task 1.1.3**: Configure AI service integration
- Duration: 30 minutes
- Setup OpenAI API client with environment variables
- Create initial AI service wrapper
- Configure API key management
- Add retry logic and error handling
- Create `.env.example` with required keys

**Task 1.1.4**: Setup database schema foundation
- Duration: 30 minutes
- Create migrations for core tables: students, ai_conversations, practice_assignments
- Add indexes for performance
- Run migrations and verify setup
- Create seed data for testing

#### Phase 1.2: AI Conversation Service (180 minutes)

**Task 1.2.1**: Create conversation model and controller
- Duration: 45 minutes
- Create `AiConversation` model with associations to Student
- Create API controller for conversation endpoints
- Implement create conversation endpoint
- Implement send message endpoint
- Add basic validation and error handling

**Task 1.2.2**: Implement OpenAI conversation service
- Duration: 60 minutes
- Create `ConversationService` class
- Integrate OpenAI ChatCompletion API
- Implement system prompt for educational assistant persona
- Add conversation history management
- Handle API errors and retries

**Task 1.2.3**: Implement basic memory system
- Duration: 45 minutes
- Create `MemoryService` for storing conversation context
- Implement conversation buffer (last 10 messages)
- Store conversations in database
- Add retrieval of recent conversation history
- Test memory persistence

**Task 1.2.4**: Create React conversation UI
- Duration: 30 minutes
- Build `CompanionChat` component with message list
- Implement message input and send functionality
- Add loading states and error handling
- Style with existing Nerdy design system
- Connect to WebSocket for real-time updates

#### Phase 1.3: Practice Assignment System (150 minutes)

**Task 1.3.1**: Create practice assignment models
- Duration: 30 minutes
- Create `PracticeAssignment` model
- Create `PracticeQuestion` model
- Add associations and validations
- Create database migrations

**Task 1.3.2**: Implement basic practice generator
- Duration: 60 minutes
- Create `PracticeGeneratorService`
- Use OpenAI to generate practice questions based on subject
- Implement adaptive difficulty levels (beginner, intermediate, advanced)
- Store generated practices in database
- Add validation for question quality

**Task 1.3.3**: Create practice assignment API
- Duration: 30 minutes
- Create API controller for practice assignments
- Implement assign practice endpoint
- Implement get student practices endpoint
- Add completion tracking

**Task 1.3.4**: Build practice assignment UI
- Duration: 30 minutes
- Create `PracticeAssignments` component
- Display assigned practices to students
- Implement practice completion interface
- Show practice history

#### Phase 1.4: Basic Progress Tracking (90 minutes)

**Task 1.4.1**: Create learning goal model
- Duration: 30 minutes
- Create `LearningGoal` model
- Add associations to Student and Subject
- Create goal status tracking (active, completed, paused)
- Add database migrations

**Task 1.4.2**: Implement progress tracking API
- Duration: 30 minutes
- Create progress controller
- Implement get student progress endpoint
- Calculate progress metrics (completion rate, time spent)
- Return progress data in JSON format

**Task 1.4.3**: Build basic progress UI
- Duration: 30 minutes
- Create `ProgressTracking` component
- Display single goal progress
- Show completion percentage
- Add basic progress visualization

#### Phase 1.5: Integration Testing & MVP Demo (90 minutes)

**Task 1.5.1**: Write integration tests for conversation flow
- Duration: 30 minutes
- Test conversation creation
- Test message sending and AI response
- Test memory retrieval
- Verify WebSocket updates

**Task 1.5.2**: Write integration tests for practice system
- Duration: 30 minutes
- Test practice generation
- Test practice assignment
- Test practice completion
- Verify progress updates

**Task 1.5.3**: Create MVP demo script and cue card
- Duration: 30 minutes
- Write 3-minute demo video script showcasing:
  - AI conversation interface
  - Practice assignment functionality
  - Basic progress tracking
- Create cue card with narration and bullet points
- Highlight core MVP features

---

### Phase 2: Early Submission (Due Friday, November 7, 2025)

**Objective**: Add retention enhancement features and multi-goal tracking

#### Phase 2.1: Goal Suggestion System (150 minutes)

**Task 2.1.1**: Implement goal completion detection
- Duration: 30 minutes
- Create service to detect when goals are completed
- Add event listener for goal status changes
- Trigger suggestion service on completion

**Task 2.1.2**: Build subject suggestion service
- Duration: 60 minutes
- Create `GoalSuggestionService`
- Implement logic for subject suggestions:
  - SAT complete → college essays, study skills, AP prep
  - Chemistry → physics, STEM subjects
  - General subject → related subjects
- Use OpenAI to generate contextual suggestions
- Store suggestions in database

**Task 2.1.3**: Create suggestion UI
- Duration: 30 minutes
- Build `SubjectSuggestions` component
- Display suggestions when goal completes
- Allow students to accept suggestions as new goals
- Add "Not interested" option

**Task 2.1.4**: Add suggestion analytics
- Duration: 30 minutes
- Track suggestion acceptance rate
- Monitor which suggestions convert to new goals
- Store analytics for future improvement

#### Phase 2.2: Session Nudge System (120 minutes)

**Task 2.2.1**: Implement nudge detection logic
- Duration: 30 minutes
- Create `NudgeService` to check student conditions
- Detect students with <3 sessions by Day 7
- Schedule nudge checks (daily job)

**Task 2.2.2**: Create nudge generation
- Duration: 30 minutes
- Generate personalized nudge messages using AI
- Include booking link and session benefits
- Store nudge history

**Task 2.2.3**: Build nudge delivery system
- Duration: 30 minutes
- Integrate with existing Nerdy notification system
- Send nudges via email or in-app notification
- Track nudge delivery and response

**Task 2.2.4**: Create nudge UI component
- Duration: 30 minutes
- Display nudge notifications in UI
- Show "Book Session" CTA
- Track nudge interactions

#### Phase 2.3: Multi-Goal Progress Tracking (150 minutes)

**Task 2.3.1**: Extend progress model for multiple goals
- Duration: 30 minutes
- Update database schema to support multiple goals per student
- Add goal prioritization and ordering
- Update associations

**Task 2.3.2**: Implement multi-goal progress API
- Duration: 45 minutes
- Create endpoint to get all student goals with progress
- Calculate progress across all goals
- Return aggregated metrics
- Support filtering by goal status

**Task 2.3.3**: Build multi-goal progress UI
- Duration: 45 minutes
- Update `ProgressTracking` component
- Display multiple goals in dashboard view
- Show progress for each goal
- Add goal switching/tabs
- Visualize overall progress

**Task 2.3.4**: Add progress comparison
- Duration: 30 minutes
- Compare progress across goals
- Show fastest progressing goal
- Highlight goals needing attention

#### Phase 2.4: Unit Testing & Integration Testing (90 minutes)

**Task 2.4.1**: Write unit tests for goal suggestion service
- Duration: 30 minutes
- Test suggestion logic for different subjects
- Test suggestion generation
- Test suggestion acceptance flow

**Task 2.4.2**: Write unit tests for nudge service
- Duration: 30 minutes
- Test nudge detection logic
- Test nudge generation
- Test nudge delivery

**Task 2.4.3**: Write integration tests for multi-goal tracking
- Duration: 30 minutes
- Test multi-goal progress calculation
- Test progress API endpoints
- Test UI components with multiple goals

#### Phase 2.5: Early Submission Demo Script & Cue Card (60 minutes)

**Task 2.5.1**: Create early submission demo script
- Duration: 30 minutes
- Write 3-minute demo video script showcasing:
  - Goal completion and subject suggestions
  - Session nudge system
  - Multi-goal progress tracking
  - Retention features working together
- Create cue card with narration and bullet points
- Highlight retention enhancement features

**Task 2.5.2**: Prepare demo environment
- Duration: 30 minutes
- Set up test data for demo
- Prepare sample scenarios
- Verify all features work for recording

---

### Phase 3: Final Submission (Due Sunday, November 9, 2025)

**Objective**: Add session recording integration, analytics, and production readiness

#### Phase 3.1: Session Recording Integration (180 minutes)

**Task 3.1.1**: Setup session recording API integration
- Duration: 45 minutes
- Integrate with existing Nerdy session recording API
- Create service to fetch session recordings
- Handle authentication and authorization
- Add error handling for API failures

**Task 3.1.2**: Implement session transcription
- Duration: 45 minutes
- Integrate OpenAI Whisper API (or existing service)
- Create `SessionAnalyzerService` to process recordings
- Transcribe audio to text
- Store transcriptions in database

**Task 3.1.3**: Implement session analysis
- Duration: 60 minutes
- Use AI to analyze session transcripts
- Extract key learning points
- Identify topics covered
- Detect student strengths and weaknesses
- Store analysis results

**Task 3.1.4**: Integrate session analysis into memory
- Duration: 30 minutes
- Update `MemoryService` to include session insights
- Store session analysis in conversation context
- Enable AI to reference past sessions
- Test memory retrieval with session data

#### Phase 3.2: Analytics Dashboard (150 minutes)

**Task 3.2.1**: Create analytics data models
- Duration: 30 minutes
- Design analytics schema
- Create metrics tables (engagement, retention, learning improvements)
- Add indexes for query performance

**Task 3.2.2**: Implement analytics collection
- Duration: 45 minutes
- Create service to collect metrics:
  - Conversation frequency
  - Practice completion rates
  - Goal completion rates
  - Session engagement metrics
- Schedule daily analytics jobs

**Task 3.2.3**: Build analytics API
- Duration: 45 minutes
- Create analytics controller
- Implement endpoints for:
  - Student analytics
  - Cohort analytics
  - Retention metrics
  - Learning improvement tracking
- Add data aggregation logic

**Task 3.2.4**: Create analytics dashboard UI
- Duration: 30 minutes
- Build `AnalyticsDashboard` component
- Display key metrics with charts
- Show learning improvement trends
- Add date range filtering

#### Phase 3.3: Production Hardening (120 minutes)

**Task 3.3.1**: Add error handling and logging
- Duration: 30 minutes
- Implement comprehensive error handling
- Add logging for all AI API calls
- Log errors with context
- Setup error monitoring (Sentry or similar)

**Task 3.3.2**: Implement rate limiting
- Duration: 30 minutes
- Add rate limiting for API endpoints
- Protect OpenAI API calls from abuse
- Add queue management for background jobs

**Task 3.3.3**: Add caching layer
- Duration: 30 minutes
- Cache frequently accessed data (student progress, practice assignments)
- Implement Redis caching
- Add cache invalidation strategies
- Optimize database queries

**Task 3.3.4**: Performance optimization
- Duration: 30 minutes
- Optimize database queries (add missing indexes)
- Implement pagination for large datasets
- Optimize AI API calls (batch when possible)
- Add performance monitoring

#### Phase 3.4: Documentation & Deployment (120 minutes)

**Task 3.4.1**: Write AI prompting strategies documentation
- Duration: 30 minutes
- Document all AI prompts used
- Explain prompting strategies
- Document system prompts for different services
- Include examples of effective prompts

**Task 3.4.2**: Create integration guide
- Duration: 30 minutes
- Document Rails/React integration points
- Explain API endpoints
- Document WebSocket setup
- Include troubleshooting guide

**Task 3.4.3**: Deploy to cloud (AWS or Vercel)
- Duration: 30 minutes
- Deploy backend to AWS (or Heroku/Railway)
- Deploy frontend to Vercel
- Configure environment variables
- Verify deployment works

**Task 3.4.4**: Create cost analysis document
- Duration: 30 minutes
- Analyze OpenAI API costs
- Estimate monthly costs for production
- Document cost optimization strategies
- Create cost projection for 90-day roadmap

#### Phase 3.5: Comprehensive Testing (90 minutes)

**Task 3.5.1**: Write end-to-end tests
- Duration: 30 minutes
- Test complete user flows:
  - Student starts conversation
  - Gets practice assignment
  - Completes goal
  - Receives suggestion
- Test session recording integration flow

**Task 3.5.2**: Write unit tests for all services
- Duration: 30 minutes
- Test all AI services
- Test retention services
- Test analytics services
- Achieve >80% code coverage

**Task 3.5.3**: Performance testing
- Duration: 30 minutes
- Test API response times
- Test concurrent user handling
- Test AI API rate limits
- Verify system can handle expected load

#### Phase 3.6: 90-Day Roadmap & Final Demo (90 minutes)

**Task 3.6.1**: Create 90-day implementation roadmap
- Duration: 30 minutes
- Document phased rollout plan
- Identify dependencies and blockers
- Estimate resource requirements
- Define success metrics for each phase

**Task 3.6.2**: Create final demo video script and cue card
- Duration: 30 minutes
- Write 3-minute demo video script showcasing:
  - Complete AI companion functionality
  - Session recording integration
  - Analytics dashboard
  - Retention features in action
- Create cue card with narration and bullet points
- Highlight production-ready features

**Task 3.6.3**: Final system walkthrough
- Duration: 30 minutes
- Verify all features work end-to-end
- Test demo scenario
- Prepare demo environment
- Document any known issues

---

## Success Metrics

### Technical Metrics
- ✅ AI conversation response time < 3 seconds
- ✅ Practice generation time < 5 seconds
- ✅ System uptime > 99%
- ✅ API response time < 500ms (95th percentile)

### Business Metrics
- ✅ Address 52% "goal achieved" churn through suggestions
- ✅ Increase session booking rate for <3 session students by 20%
- ✅ Improve student engagement (daily active users)
- ✅ Generate measurable learning improvements (test scores, completion rates)

### AI Metrics
- ✅ Conversation quality score > 4.0/5.0 (student ratings)
- ✅ Practice relevance score > 85%
- ✅ Suggestion acceptance rate > 30%
- ✅ AI response accuracy > 90%

---

## Risk Assessment & Mitigation

### Risk 1: OpenAI API Rate Limits
- **Probability**: Medium
- **Impact**: High
- **Mitigation**: Implement rate limiting, caching, and queue management

### Risk 2: Session Recording API Integration Issues
- **Probability**: Medium
- **Impact**: Medium
- **Mitigation**: Create fallback mock service, implement retry logic

### Risk 3: AI Response Quality
- **Probability**: Low
- **Impact**: High
- **Mitigation**: Iterative prompt engineering, user feedback loop, A/B testing

### Risk 4: Database Performance
- **Probability**: Low
- **Impact**: Medium
- **Mitigation**: Proper indexing, caching, query optimization

---

## Dependencies

### External Dependencies
- OpenAI API access and credits
- Existing Nerdy Rails/React platform access
- Session recording API access
- PostgreSQL database access

### Internal Dependencies
- Design system components
- Authentication system
- Notification system
- WebSocket infrastructure

---

## Appendix: AI Prompting Strategies

### Conversation System Prompt Template
```
You are an educational AI companion helping students between tutoring sessions. 
Your role is to:
- Answer questions conversationally and clearly
- Reference past lessons and sessions when relevant
- Encourage learning and practice
- Guide students back to human tutors for complex topics

Remember: [CONTEXT FROM MEMORY]
Student's current goals: [GOALS]
Recent sessions: [SESSION_SUMMARY]
```

### Practice Generation Prompt Template
```
Generate [NUMBER] practice questions for [SUBJECT] at [DIFFICULTY] level.
Based on: [SESSION_ANALYSIS]
Topics covered: [TOPICS]
Student level: [LEVEL]

Format: Multiple choice questions with explanations.
```

### Goal Suggestion Prompt Template
```
Student just completed: [COMPLETED_GOAL]
Suggest 3 related learning goals that would:
- Build on their success
- Address common next steps
- Keep them engaged

Context: [STUDENT_HISTORY]
```

---

*Document Version: 1.0*  
*Created: November 3, 2025*  
*Last Updated: November 3, 2025*  
*Status: Ready for Execution*

```

Creating the PRD for Option B: Tutor Quality Scoring System:


```markdown
# Product Requirements Document: Tutor Quality Scoring System

**Version:** 1.0  
**Date:** November 3, 2025  
**Project Duration:** 7 Days (Nov 3 - Nov 9, 2025)  
**Project Start:** November 3, 2025  
**Framework:** Based on October 16, 2025 success path methodology  
**Target:** Automated tutor performance evaluation and coaching system

---

## Executive Summary

Tutor Quality Scoring System is an automated evaluation platform that assesses tutor performance across every session, identifies coaching opportunities, predicts which tutors will churn, and recommends interventions. The system processes 3,000 daily sessions and provides actionable insights within 1 hour of session completion, addressing critical retention and quality issues.

**Key Deliverables:**
- ✅ Automated tutor performance scoring across all sessions
- ✅ Coaching opportunity identification
- ✅ Tutor churn prediction model
- ✅ Intervention recommendations
- ✅ Real-time performance dashboard
- ✅ First session quality detection (24% churn prevention)
- ✅ Rescheduling rate analysis (98.2% tutor-initiated detection)
- ✅ No-show risk identification (16% replacement prevention)

**Success Targets:**
- **MVP (Nov 4)**: Core scoring system, basic session analysis, simple dashboard
- **Early Submission (Nov 7)**: + Churn prediction, intervention recommendations, retention features
- **Final Submission (Nov 9)**: + Full analytics dashboard, coaching insights, comprehensive testing

**Business Impact:**
- Prevents 24% of churners through first session quality detection
- Identifies 98.2% of tutor-initiated reschedules
- Reduces 16% of tutor replacements through no-show prediction
- Processes 3,000 sessions/day with <1 hour latency

---

## Project Timeline

| Milestone | Date | Deliverable |
|-----------|------|-------------|
| **Phase 1: MVP** | Tuesday, November 4, 2025 | Core scoring system, session analysis, basic dashboard |
| **Early Submission** | Friday, November 7, 2025 | + Churn prediction, interventions, retention features |
| **Final Submission** | Sunday, November 9, 2025 | + Full analytics, coaching insights, comprehensive testing, demo video |

---

## Technology Stack

### AI/ML Stack
- **LLM Provider**: OpenAI GPT-4 for session analysis and scoring
- **ML Framework**: scikit-learn (Python) for churn prediction model
- **Embeddings**: OpenAI text-embedding-3-small for semantic analysis
- **Vector Database**: PostgreSQL with pgvector for session similarity search
- **ML Pipeline**: Python scripts for model training and prediction

### Backend Stack
- **Framework**: Ruby on Rails 7+ (integrates with existing platform)
- **API**: RESTful API + GraphQL for complex queries
- **Background Jobs**: Sidekiq for async processing (session analysis, scoring)
- **Database**: PostgreSQL (existing Nerdy infrastructure)
- **Caching**: Redis for session data and model predictions
- **Python Integration**: Python microservice for ML models (via HTTP API)

### Frontend Stack
- **Framework**: React 18+ (integrates with existing platform)
- **State Management**: React Query for server state, Zustand for client state
- **UI Components**: Existing Nerdy design system components
- **Charts**: Recharts or Chart.js for analytics visualization
- **Real-time**: Action Cable (WebSocket) for live updates

### Integration Stack
- **Session Data**: Existing Nerdy API for session information
- **Tutor Data**: Existing Nerdy API for tutor profiles
- **Rescheduling Data**: Existing Nerdy API for booking data
- **Authentication**: Existing Nerdy authentication system

### Development Tools
- **Testing**: RSpec (backend), Jest + React Testing Library (frontend), pytest (Python ML)
- **Linting**: ESLint, RuboCop, pylint
- **Type Checking**: TypeScript for React, Sorbet for Ruby (optional)
- **Documentation**: JSDoc, YARD

---

## Architecture Overview

### System Components

```
tutor-quality-scoring/
├── backend/
│   ├── app/
│   │   ├── models/
│   │   │   ├── tutor.rb
│   │   │   ├── session.rb
│   │   │   ├── tutor_score.rb
│   │   │   ├── coaching_opportunity.rb
│   │   │   ├── churn_prediction.rb
│   │   │   └── intervention.rb
│   │   ├── controllers/
│   │   │   ├── api/
│   │   │   │   ├── tutor_scores_controller.rb
│   │   │   │   ├── coaching_controller.rb
│   │   │   │   └── predictions_controller.rb
│   │   ├── services/
│   │   │   ├── scoring/
│   │   │   │   ├── session_scorer_service.rb
│   │   │   │   ├── quality_analyzer_service.rb
│   │   │   │   └── first_session_analyzer.rb
│   │   │   ├── prediction/
│   │   │   │   ├── churn_predictor_service.rb
│   │   │   │   └── no_show_predictor_service.rb
│   │   │   └── retention/
│   │   │       ├── reschedule_analyzer_service.rb
│   │   │       └── intervention_service.rb
│   │   └── jobs/
│   │       ├── session_scoring_job.rb
│   │       ├── churn_prediction_job.rb
│   │       └── intervention_generation_job.rb
│   ├── db/
│   │   ├── migrate/
│   │   └── schema.rb
│   └── spec/
├── ml-service/
│   ├── models/
│   │   ├── churn_predictor.py
│   │   └── no_show_predictor.py
│   ├── services/
│   │   ├── model_training.py
│   │   └── prediction_service.py
│   └── tests/
├── frontend/
│   ├── src/
│   │   ├── components/
│   │   │   ├── TutorScores/
│   │   │   ├── CoachingOpportunities/
│   │   │   ├── ChurnPredictions/
│   │   │   ├── Interventions/
│   │   │   └── AnalyticsDashboard/
│   │   ├── services/
│   │   │   ├── api.ts
│   │   │   └── websocket.ts
│   │   └── hooks/
│   │       ├── useTutorScores.ts
│   │       └── usePredictions.ts
│   └── __tests__/
└── docs/
    ├── ai-prompting-strategies.md
    └── ml-model-documentation.md
```

### Data Flow

1. **Session Scoring Flow**: Session ends → Job queued → AI analyzes session → Score calculated → Stored in database
2. **Churn Prediction Flow**: Daily job runs → Feature extraction → ML model prediction → Risk score assigned → Intervention triggered
3. **Coaching Flow**: Poor session detected → Coaching opportunity identified → Recommendations generated → Delivered to manager
4. **Intervention Flow**: High-risk tutor identified → Intervention service generates recommendations → Alerts sent → Actions tracked

---

## Phase Breakdown

### Phase 1: MVP (Due Tuesday, November 4, 2025)

**Objective**: Core scoring system working end-to-end

#### Phase 1.1: Project Setup & Foundation (120 minutes)

**Task 1.1.1**: Initialize Rails API backend
- Duration: 30 minutes
- Create new Rails API app or integrate with existing Nerdy platform
- Configure PostgreSQL database
- Setup basic API structure with versioning (api/v1/)
- Install dependencies: `gem 'openai', gem 'sidekiq', gem 'pgvector'`
- PowerShell: `rails new tutor_quality_scoring --api --database=postgresql`

**Task 1.1.2**: Setup Python ML service
- Duration: 30 minutes
- Create Python microservice directory structure
- Initialize virtual environment
- Install dependencies: `pip install scikit-learn pandas numpy openai`
- Create FastAPI or Flask API for ML service
- Setup HTTP communication with Rails backend

**Task 1.1.3**: Setup React frontend integration
- Duration: 30 minutes
- Create React components directory structure
- Setup React Query for API communication
- Configure WebSocket connection (Action Cable)
- Install dependencies: `npm install @tanstack/react-query axios recharts`
- Create base API service client

**Task 1.1.4**: Setup database schema foundation
- Duration: 30 minutes
- Create migrations for core tables: tutors, sessions, tutor_scores
- Add indexes for performance (tutor_id, session_id, created_at)
- Run migrations and verify setup
- Create seed data for testing

#### Phase 1.2: Session Scoring System (180 minutes)

**Task 1.2.1**: Create scoring models and schema
- Duration: 30 minutes
- Create `TutorScore` model with associations
- Design scoring schema (quality_score, engagement_score, technical_score, etc.)
- Create database migrations
- Add validations and constraints

**Task 1.2.2**: Implement basic session analyzer
- Duration: 60 minutes
- Create `SessionAnalyzerService` class
- Integrate with existing Nerdy session API
- Extract session data (duration, transcript, ratings, student feedback)
- Parse session metadata
- Store raw session data

**Task 1.2.3**: Implement AI-powered scoring service
- Duration: 60 minutes
- Create `SessionScorerService` class
- Use OpenAI to analyze session transcripts
- Generate quality scores based on:
  - Teaching effectiveness
  - Student engagement
  - Communication clarity
  - Technical accuracy
- Store scores in database

**Task 1.2.4**: Create scoring job processor
- Duration: 30 minutes
- Create `SessionScoringJob` Sidekiq job
- Process sessions in background
- Handle job failures and retries
- Queue processing for 3,000 sessions/day
- Ensure <1 hour latency

#### Phase 1.3: Basic Dashboard (150 minutes)

**Task 1.3.1**: Create scoring API endpoints
- Duration: 45 minutes
- Create API controller for tutor scores
- Implement get tutor scores endpoint
- Implement get session score endpoint
- Add filtering and pagination
- Return JSON with scores and metadata

**Task 1.3.2**: Build tutor scores UI component
- Duration: 45 minutes
- Create `TutorScores` React component
- Display tutor score cards with metrics
- Show score history over time
- Add score breakdown visualization
- Style with existing Nerdy design system

**Task 1.3.3**: Create basic analytics dashboard
- Duration: 60 minutes
- Build `AnalyticsDashboard` component
- Display aggregate tutor scores
- Show score distribution charts
- Add basic filtering (date range, tutor)
- Display top/bottom performing tutors

#### Phase 1.4: First Session Quality Detection (90 minutes)

**Task 1.4.1**: Implement first session analyzer
- Duration: 45 minutes
- Create `FirstSessionAnalyzerService`
- Detect first sessions for students
- Analyze quality indicators:
  - Engagement level
  - Communication clarity
  - Student satisfaction signals
  - Technical issues
- Flag poor first sessions

**Task 1.4.2**: Create first session alerts
- Duration: 30 minutes
- Create alert system for poor first sessions
- Generate alert notifications
- Store alerts in database
- Integrate with notification system

**Task 1.4.3**: Build first session UI
- Duration: 15 minutes
- Add first session alerts to dashboard
- Display poor first session indicators
- Show alert history

#### Phase 1.5: Integration Testing & MVP Demo (90 minutes)

**Task 1.5.1**: Write integration tests for scoring flow
- Duration: 30 minutes
- Test session scoring job
- Test score calculation
- Test API endpoints
- Verify <1 hour latency

**Task 1.5.2**: Write integration tests for dashboard
- Duration: 30 minutes
- Test API endpoints
- Test UI components
- Test real-time updates
- Verify data accuracy

**Task 1.5.3**: Create MVP demo script and cue card
- Duration: 30 minutes
- Write 3-minute demo video script showcasing:
  - Session scoring system
  - Tutor scores dashboard
  - First session quality detection
  - Basic analytics
- Create cue card with narration and bullet points
- Highlight core MVP features

---

### Phase 2: Early Submission (Due Friday, November 7, 2025)

**Objective**: Add churn prediction, interventions, and retention features

#### Phase 2.1: Churn Prediction System (180 minutes)

**Task 2.1.1**: Create churn prediction data model
- Duration: 30 minutes
- Design feature extraction schema
- Create `ChurnPrediction` model
- Store prediction results and confidence scores
- Add database migrations

**Task 2.1.2**: Implement feature extraction service
- Duration: 60 minutes
- Create `FeatureExtractionService` (Python)
- Extract features from tutor data:
  - Session frequency trends
  - Score trends (declining performance)
  - Rescheduling patterns
  - Student feedback trends
  - Engagement metrics
- Store features in database

**Task 2.1.3**: Build churn prediction ML model
- Duration: 60 minutes
- Create `ChurnPredictor` Python model
- Train model on historical tutor data (if available)
- Use scikit-learn (Random Forest or XGBoost)
- Implement prediction API endpoint
- Return risk score (0-1) and confidence

**Task 2.1.4**: Integrate churn prediction into Rails
- Duration: 30 minutes
- Create `ChurnPredictorService` in Rails
- Call Python ML service API
- Store predictions in database
- Schedule daily prediction job

#### Phase 2.2: Intervention System (150 minutes)

**Task 2.2.1**: Create intervention model
- Duration: 30 minutes
- Create `Intervention` model
- Store intervention recommendations
- Add intervention types (coaching, support, resource)
- Create database migrations

**Task 2.2.2**: Implement intervention generation service
- Duration: 60 minutes
- Create `InterventionService` class
- Use OpenAI to generate personalized recommendations
- Generate interventions based on:
  - Low scores
  - Churn risk
  - Specific coaching needs
  - Performance trends
- Store recommendations

**Task 2.2.3**: Create intervention delivery system
- Duration: 30 minutes
- Integrate with notification system
- Send interventions to managers
- Track intervention delivery
- Store intervention history

**Task 2.2.4**: Build intervention UI
- Duration: 30 minutes
- Create `Interventions` component
- Display recommended interventions
- Show intervention history
- Add action tracking (completed, dismissed)

#### Phase 2.3: Rescheduling Analysis (120 minutes)

**Task 2.3.1**: Implement reschedule analyzer
- Duration: 45 minutes
- Create `RescheduleAnalyzerService`
- Integrate with existing booking API
- Analyze rescheduling patterns:
  - Tutor-initiated vs student-initiated
  - Frequency of reschedules
  - Patterns (time of day, day of week)
- Flag high rescheduling tutors

**Task 2.3.2**: Create rescheduling alerts
- Duration: 30 minutes
- Generate alerts for tutors with high rescheduling rates
- Detect patterns indicating churn risk
- Store alerts in database
- Integrate with notification system

**Task 2.3.3**: Build rescheduling UI
- Duration: 45 minutes
- Create `ReschedulingAnalysis` component
- Display rescheduling statistics
- Show tutor rescheduling patterns
- Highlight high-risk tutors
- Add filtering and sorting

#### Phase 2.4: No-Show Prediction (120 minutes)

**Task 2.4.1**: Implement no-show predictor
- Duration: 45 minutes
- Create `NoShowPredictorService` (Python)
- Build ML model for no-show prediction
- Extract features:
  - Historical no-show rate
  - Recent cancelation patterns
  - Scheduling patterns
  - Engagement metrics
- Return risk score

**Task 2.4.2**: Integrate no-show prediction
- Duration: 30 minutes
- Integrate Python model into Rails
- Schedule prediction job
- Store predictions in database
- Generate alerts for high-risk tutors

**Task 2.4.3**: Create no-show UI
- Duration: 45 minutes
- Build `NoShowPredictions` component
- Display no-show risk scores
- Show historical no-show data
- Highlight at-risk tutors
- Add intervention recommendations

#### Phase 2.5: Unit Testing & Integration Testing (90 minutes)

**Task 2.5.1**: Write unit tests for churn prediction
- Duration: 30 minutes
- Test feature extraction
- Test ML model prediction
- Test prediction service integration
- Verify prediction accuracy

**Task 2.5.2**: Write unit tests for intervention system
- Duration: 30 minutes
- Test intervention generation
- Test intervention delivery
- Test intervention tracking

**Task 2.5.3**: Write integration tests for retention features
- Duration: 30 minutes
- Test rescheduling analysis
- Test no-show prediction
- Test end-to-end retention flow

#### Phase 2.6: Early Submission Demo Script & Cue Card (60 minutes)

**Task 2.6.1**: Create early submission demo script
- Duration: 30 minutes
- Write 3-minute demo video script showcasing:
  - Churn prediction system
  - Intervention recommendations
  - Rescheduling analysis
  - No-show prediction
  - Retention features working together
- Create cue card with narration and bullet points
- Highlight retention enhancement features

**Task 2.6.2**: Prepare demo environment
- Duration: 30 minutes
- Set up test data for demo
- Prepare sample scenarios
- Verify all features work for recording

---

### Phase 3: Final Submission (Due Sunday, November 9, 2025)

**Objective**: Full analytics, coaching insights, and production readiness

#### Phase 3.1: Coaching Opportunity System (180 minutes)

**Task 3.1.1**: Create coaching opportunity model
- Duration: 30 minutes
- Create `CoachingOpportunity` model
- Store coaching recommendations
- Add opportunity types (communication, technical, engagement)
- Create database migrations

**Task 3.1.2**: Implement coaching analyzer
- Duration: 60 minutes
- Create `CoachingAnalyzerService`
- Use AI to identify specific coaching needs:
  - Communication improvements
  - Technical accuracy issues
  - Engagement techniques
  - Time management
- Generate actionable coaching points

**Task 3.1.3**: Build coaching insights API
- Duration: 45 minutes
- Create coaching controller
- Implement endpoints for:
  - Get tutor coaching opportunities
  - Get coaching recommendations
  - Track coaching progress
- Return structured coaching data

**Task 3.1.4**: Create coaching UI
- Duration: 45 minutes
- Build `CoachingOpportunities` component
- Display coaching recommendations
- Show coaching progress tracking
- Add coaching history
- Visualize coaching impact

#### Phase 3.2: Advanced Analytics Dashboard (150 minutes)

**Task 3.2.1**: Create analytics data models
- Duration: 30 minutes
- Design analytics schema
- Create metrics tables (cohort analysis, trend analysis)
- Add indexes for query performance

**Task 3.2.2**: Implement advanced analytics service
- Duration: 60 minutes
- Create `AnalyticsService` class
- Calculate metrics:
  - Tutor performance trends
  - Cohort comparisons
  - Score distributions
  - Retention metrics
- Aggregate data efficiently

**Task 3.2.3**: Build advanced analytics API
- Duration: 30 minutes
- Create analytics controller
- Implement endpoints for:
  - Cohort analytics
  - Trend analysis
  - Performance distributions
  - Retention metrics
- Add caching for performance

**Task 3.2.4**: Create advanced analytics UI
- Duration: 30 minutes
- Build `AdvancedAnalytics` component
- Display cohort comparisons
- Show trend charts
- Add interactive filters
- Visualize performance distributions

#### Phase 3.3: Production Hardening (120 minutes)

**Task 3.3.1**: Optimize for 3,000 sessions/day
- Duration: 45 minutes
- Implement job queue prioritization
- Add batch processing for scoring
- Optimize database queries
- Implement caching strategies
- Verify <1 hour latency for all sessions

**Task 3.3.2**: Add error handling and monitoring
- Duration: 30 minutes
- Implement comprehensive error handling
- Add logging for all AI API calls
- Setup error monitoring (Sentry)
- Add health check endpoints

**Task 3.3.3**: Implement rate limiting and caching
- Duration: 30 minutes
- Add rate limiting for API endpoints
- Implement Redis caching for predictions
- Cache ML model predictions
- Optimize API response times

**Task 3.3.4**: Performance optimization
- Duration: 15 minutes
- Optimize database queries
- Add missing indexes
- Implement pagination
- Add performance monitoring

#### Phase 3.4: Documentation & Deployment (120 minutes)

**Task 3.4.1**: Write AI prompting strategies documentation
- Duration: 30 minutes
- Document all AI prompts used
- Explain prompting strategies for scoring
- Document coaching recommendation prompts
- Include examples

**Task 3.4.2**: Create ML model documentation
- Duration: 30 minutes
- Document churn prediction model
- Document no-show prediction model
- Explain feature engineering
- Document model training process

**Task 3.4.3**: Create integration guide
- Duration: 30 minutes
- Document Rails/React integration
- Document Python ML service integration
- Explain API endpoints
- Include troubleshooting guide

**Task 3.4.4**: Deploy to cloud (AWS or Vercel)
- Duration: 30 minutes
- Deploy backend to AWS (or Heroku/Railway)
- Deploy Python ML service
- Deploy frontend to Vercel
- Configure environment variables
- Verify deployment works

#### Phase 3.5: Comprehensive Testing (90 minutes)

**Task 3.5.1**: Write end-to-end tests
- Duration: 30 minutes
- Test complete scoring flow
- Test churn prediction flow
- Test intervention delivery
- Test analytics dashboard

**Task 3.5.2**: Write unit tests for all services
- Duration: 30 minutes
- Test all scoring services
- Test prediction services
- Test retention services
- Achieve >80% code coverage

**Task 3.5.3**: Performance testing
- Duration: 30 minutes
- Test 3,000 sessions/day processing
- Test API response times
- Test concurrent user handling
- Verify <1 hour latency

#### Phase 3.6: Cost Analysis & Final Demo (90 minutes)

**Task 3.6.1**: Create cost analysis document
- Duration: 30 minutes
- Analyze OpenAI API costs
- Estimate ML service hosting costs
- Document cost optimization strategies
- Create cost projection for production

**Task 3.6.2**: Create final demo video script and cue card
- Duration: 30 minutes
- Write 3-minute demo video script showcasing:
  - Complete scoring system
  - Churn prediction in action
  - Coaching opportunities
  - Advanced analytics dashboard
  - Retention features
- Create cue card with narration and bullet points
- Highlight production-ready features

**Task 3.6.3**: Final system walkthrough
- Duration: 30 minutes
- Verify all features work end-to-end
- Test with sample 3,000 sessions
- Verify <1 hour processing time
- Prepare demo environment

---

## Success Metrics

### Technical Metrics
- ✅ Process 3,000 sessions/day
- ✅ <1 hour latency from session completion to insights
- ✅ System uptime > 99%
- ✅ API response time < 500ms (95th percentile)
- ✅ ML model prediction accuracy > 85%

### Business Metrics
- ✅ Identify 24% of churners through first session detection
- ✅ Flag 98.2% of tutor-initiated reschedules
- ✅ Predict 16% of no-shows with >80% accuracy
- ✅ Generate actionable interventions for >90% of at-risk tutors

### Quality Metrics
- ✅ Scoring accuracy > 90% (validated against human reviewers)
- ✅ Churn prediction precision > 80%
- ✅ Coaching recommendation relevance > 85%
- ✅ Intervention acceptance rate > 60%

---

## Risk Assessment & Mitigation

### Risk 1: Processing 3,000 Sessions/Day
- **Probability**: Medium
- **Impact**: High
- **Mitigation**: Implement job queue prioritization, batch processing, horizontal scaling

### Risk 2: ML Model Accuracy
- **Probability**: Medium
- **Impact**: High
- **Mitigation**: Iterative model training, feature engineering, validation against historical data

### Risk 3: OpenAI API Rate Limits
- **Probability**: Medium
- **Impact**: Medium
- **Mitigation**: Implement rate limiting, caching, queue management, batch API calls

### Risk 4: Integration with Existing Platform
- **Probability**: Low
- **Impact**: Medium
- **Mitigation**: Create API wrapper, implement retry logic, handle API failures gracefully

---

## Dependencies

### External Dependencies
- OpenAI API access and credits
- Existing Nerdy Rails/React platform access
- Session data API access
- Tutor and booking data API access
- PostgreSQL database access

### Internal Dependencies
- Design system components
- Authentication system
- Notification system
- WebSocket infrastructure
- Python ML service hosting

---

## Appendix: AI Prompting Strategies

### Session Scoring Prompt Template
```
Analyze this tutoring session transcript and provide scores (1-10) for:
1. Teaching Effectiveness
2. Student Engagement
3. Communication Clarity
4. Technical Accuracy

Transcript: [SESSION_TRANSCRIPT]
Student Feedback: [FEEDBACK]
Session Duration: [DURATION]

Provide scores and brief justification for each category.
```

### Coaching Recommendation Prompt Template
```
Based on this tutor's performance data, identify 3 specific coaching opportunities:
- Recent scores: [SCORES]
- Common issues: [ISSUES]
- Student feedback: [FEEDBACK]

Provide actionable coaching recommendations with specific examples.
```

### Intervention Generation Prompt Template
```
This tutor has a churn risk score of [RISK_SCORE]. Generate personalized intervention recommendations:
- Performance trends: [TRENDS]
- Specific issues: [ISSUES]
- Engagement level: [ENGAGEMENT]

Provide 3-5 specific intervention actions with expected outcomes.
```

---

*Document Version: 1.0*  
*Created: November 3, 2025*  
*Last Updated: November 3, 2025*  
*Status: Ready for Execution*

```

Creating the PRD for Option C: Intelligent Operations Dashboard:


```markdown
# Product Requirements Document: Intelligent Operations Dashboard

**Version:** 1.0  
**Date:** November 3, 2025  
**Project Duration:** 7 Days (Nov 3 - Nov 9, 2025)  
**Project Start:** November 3, 2025  
**Framework:** Based on October 16, 2025 success path methodology  
**Target:** Real-time command center for marketplace health monitoring

---

## Executive Summary

Intelligent Operations Dashboard is a real-time command center that monitors marketplace health, predicts supply/demand imbalances, automatically adjusts tutor recruiting campaigns, and alerts operators to anomalies. The system handles 50+ data streams and provides explainable AI recommendations, addressing critical operational challenges and retention issues.

**Key Deliverables:**
- ✅ Real-time marketplace health monitoring
- ✅ Supply/demand prediction and balancing
- ✅ Automated tutor recruiting campaign adjustments
- ✅ Anomaly detection and alerts
- ✅ Customer health score dashboard
- ✅ First session success rate tracking by tutor/subject
- ✅ Session velocity trends by cohort
- ✅ IB call spike alerts (≥2 calls in 14 days = churn risk)
- ✅ Churn prediction by customer segment
- ✅ Instant tutor supply vs. demand predictions
- ✅ Early warning alerts for at-risk customers

**Success Targets:**
- **MVP (Nov 4)**: Core dashboard, basic health monitoring, simple supply/demand tracking
- **Early Submission (Nov 7)**: + AI predictions, automated campaign adjustments, retention features
- **Final Submission (Nov 9)**: + Full analytics, explainable AI, comprehensive testing, demo video

**Business Impact:**
- Prevents churn through early warning alerts
- Optimizes tutor supply through demand prediction
- Improves first session success rates through insights
- Reduces operational overhead through automation

---

## Project Timeline

| Milestone | Date | Deliverable |
|-----------|------|-------------|
| **Phase 1: MVP** | Tuesday, November 4, 2025 | Core dashboard, basic health monitoring, supply/demand tracking |
| **Early Submission** | Friday, November 7, 2025 | + AI predictions, automated campaigns, retention features |
| **Final Submission** | Sunday, November 9, 2025 | + Full analytics, explainable AI, comprehensive testing, demo video |

---

## Technology Stack

### AI/ML Stack
- **LLM Provider**: OpenAI GPT-4 for explainable recommendations
- **ML Framework**: scikit-learn (Python) for supply/demand prediction
- **Time Series**: Prophet or LSTM for demand forecasting
- **Anomaly Detection**: Isolation Forest or LSTM Autoencoder
- **Embeddings**: OpenAI text-embedding-3-small for semantic analysis

### Backend Stack
- **Framework**: Ruby on Rails 7+ (integrates with existing platform)
- **API**: RESTful API + GraphQL for complex queries
- **Background Jobs**: Sidekiq for async processing (data aggregation, predictions)
- **Database**: PostgreSQL (existing Nerdy infrastructure)
- **Caching**: Redis for real-time data and predictions
- **Time Series Database**: TimescaleDB (PostgreSQL extension) for time-series data
- **Python Integration**: Python microservice for ML models (via HTTP API)

### Frontend Stack
- **Framework**: React 18+ (integrates with existing platform)
- **State Management**: React Query for server state, Zustand for client state
- **UI Components**: Existing Nerdy design system components
- **Charts**: Recharts or Chart.js for analytics visualization
- **Real-time**: Action Cable (WebSocket) for live updates
- **Dashboard Framework**: Custom dashboard with real-time widgets

### Data Integration Stack
- **Data Streams**: 50+ data sources (sessions, bookings, tutors, students, etc.)
- **API Integration**: Existing Nerdy APIs for all data sources
- **Data Aggregation**: Background jobs for real-time aggregation
- **Event Streaming**: Action Cable for real-time updates

### Development Tools
- **Testing**: RSpec (backend), Jest + React Testing Library (frontend), pytest (Python ML)
- **Linting**: ESLint, RuboCop, pylint
- **Type Checking**: TypeScript for React, Sorbet for Ruby (optional)
- **Documentation**: JSDoc, YARD

---

## Architecture Overview

### System Components

```
intelligent-operations-dashboard/
├── backend/
│   ├── app/
│   │   ├── models/
│   │   │   ├── marketplace_health.rb
│   │   │   ├── supply_demand.rb
│   │   │   ├── customer_health.rb
│   │   │   ├── prediction.rb
│   │   │   ├── alert.rb
│   │   │   └── campaign_adjustment.rb
│   │   ├── controllers/
│   │   │   ├── api/
│   │   │   │   ├── dashboard_controller.rb
│   │   │   │   ├── health_controller.rb
│   │   │   │   ├── predictions_controller.rb
│   │   │   │   └── alerts_controller.rb
│   │   ├── services/
│   │   │   ├── data/
│   │   │   │   ├── stream_aggregator_service.rb
│   │   │   │   └── data_processor_service.rb
│   │   │   ├── prediction/
│   │   │   │   ├── supply_demand_predictor_service.rb
│   │   │   │   ├── churn_predictor_service.rb
│   │   │   │   └── anomaly_detector_service.rb
│   │   │   ├── automation/
│   │   │   │   ├── campaign_adjuster_service.rb
│   │   │   │   └── alert_service.rb
│   │   │   └── retention/
│   │   │       ├── customer_health_service.rb
│   │   │       └── early_warning_service.rb
│   │   └── jobs/
│   │       ├── data_aggregation_job.rb
│   │       ├── prediction_job.rb
│   │       ├── anomaly_detection_job.rb
│   │       └── campaign_adjustment_job.rb
│   ├── db/
│   │   ├── migrate/
│   │   └── schema.rb
│   └── spec/
├── ml-service/
│   ├── models/
│   │   ├── supply_demand_predictor.py
│   │   ├── churn_predictor.py
│   │   └── anomaly_detector.py
│   ├── services/
│   │   ├── model_training.py
│   │   └── prediction_service.py
│   └── tests/
├── frontend/
│   ├── src/
│   │   ├── components/
│   │   │   ├── Dashboard/
│   │   │   ├── HealthMetrics/
│   │   │   ├── SupplyDemand/
│   │   │   ├── CustomerHealth/
│   │   │   ├── Predictions/
│   │   │   ├── Alerts/
│   │   │   └── Campaigns/
│   │   ├── services/
│   │   │   ├── api.ts
│   │   │   └── websocket.ts
│   │   └── hooks/
│   │       ├── useDashboard.ts
│   │       └── usePredictions.ts
│   └── __tests__/
└── docs/
    ├── ai-prompting-strategies.md
    └── ml-model-documentation.md
```

### Data Flow

1. **Data Aggregation Flow**: 50+ data streams → Background jobs → Aggregate and process → Store in TimescaleDB → Update dashboard
2. **Prediction Flow**: Historical data → ML models → Predict supply/demand → Generate recommendations → Store predictions
3. **Alert Flow**: Anomaly detected → Alert service → Generate alert → Send notification → Display on dashboard
4. **Campaign Flow**: Supply/demand imbalance detected → Campaign adjuster → Generate recommendations → Execute campaign adjustments → Track results

---

## Phase Breakdown

### Phase 1: MVP (Due Tuesday, November 4, 2025)

**Objective**: Core dashboard with basic health monitoring working

#### Phase 1.1: Project Setup & Foundation (120 minutes)

**Task 1.1.1**: Initialize Rails API backend
- Duration: 30 minutes
- Create new Rails API app or integrate with existing Nerdy platform
- Configure PostgreSQL with TimescaleDB extension
- Setup basic API structure with versioning (api/v1/)
- Install dependencies: `gem 'sidekiq', gem 'redis', gem 'timescaledb'`
- PowerShell: `rails new intelligent_operations_dashboard --api --database=postgresql`

**Task 1.1.2**: Setup Python ML service
- Duration: 30 minutes
- Create Python microservice directory structure
- Initialize virtual environment
- Install dependencies: `pip install scikit-learn pandas numpy prophet`
- Create FastAPI or Flask API for ML service
- Setup HTTP communication with Rails backend

**Task 1.1.3**: Setup React frontend integration
- Duration: 30 minutes
- Create React components directory structure
- Setup React Query for API communication
- Configure WebSocket connection (Action Cable)
- Install dependencies: `npm install @tanstack/react-query axios recharts`
- Create base API service client

**Task 1.1.4**: Setup database schema foundation
- Duration: 30 minutes
- Create migrations for core tables: marketplace_health, supply_demand, customer_health
- Setup TimescaleDB hypertables for time-series data
- Add indexes for performance
- Run migrations and verify setup
- Create seed data for testing

#### Phase 1.2: Data Aggregation System (180 minutes)

**Task 1.2.1**: Create data stream models
- Duration: 30 minutes
- Create models for data streams (sessions, bookings, tutors, students)
- Design data aggregation schema
- Create database migrations
- Add validations and constraints

**Task 1.2.2**: Implement data stream aggregator
- Duration: 60 minutes
- Create `StreamAggregatorService` class
- Integrate with 50+ Nerdy data APIs
- Aggregate data from multiple sources:
  - Session data
  - Booking data
  - Tutor data
  - Student data
  - Performance metrics
- Store aggregated data in TimescaleDB

**Task 1.2.3**: Create data processing jobs
- Duration: 60 minutes
- Create `DataAggregationJob` Sidekiq job
- Process data streams in background
- Aggregate data by time periods (hourly, daily)
- Handle job failures and retries
- Ensure real-time processing

**Task 1.2.4**: Implement data processor service
- Duration: 30 minutes
- Create `DataProcessorService` class
- Process and normalize aggregated data
- Calculate basic metrics (counts, averages, trends)
- Store processed data for dashboard

#### Phase 1.3: Basic Dashboard (150 minutes)

**Task 1.3.1**: Create dashboard API endpoints
- Duration: 45 minutes
- Create API controller for dashboard
- Implement get health metrics endpoint
- Implement get supply/demand data endpoint
- Add filtering and time range selection
- Return JSON with metrics

**Task 1.3.2**: Build basic dashboard UI
- Duration: 60 minutes
- Create `Dashboard` React component
- Display key health metrics:
  - Active tutors
  - Active sessions
  - Bookings
  - Supply/demand ratio
- Add real-time updates via WebSocket
- Style with existing Nerdy design system

**Task 1.3.3**: Create basic charts
- Duration: 45 minutes
- Build chart components using Recharts
- Display supply/demand trends over time
- Show marketplace health indicators
- Add basic filtering (date range, metrics)

#### Phase 1.4: Basic Supply/Demand Tracking (90 minutes)

**Task 1.4.1**: Implement supply tracking
- Duration: 30 minutes
- Create service to track tutor supply
- Calculate available tutors by subject
- Track tutor availability trends
- Store supply data in database

**Task 1.4.2**: Implement demand tracking
- Duration: 30 minutes
- Create service to track student demand
- Calculate booking requests by subject
- Track demand trends over time
- Store demand data in database

**Task 1.4.3**: Calculate supply/demand ratio
- Duration: 30 minutes
- Create service to calculate supply/demand ratios
- Identify imbalances (high demand, low supply)
- Display ratios on dashboard
- Add basic alerts for imbalances

#### Phase 1.5: Integration Testing & MVP Demo (90 minutes)

**Task 1.5.1**: Write integration tests for data aggregation
- Duration: 30 minutes
- Test data stream aggregation
- Test data processing
- Test API endpoints
- Verify real-time updates

**Task 1.5.2**: Write integration tests for dashboard
- Duration: 30 minutes
- Test dashboard API endpoints
- Test UI components
- Test WebSocket updates
- Verify data accuracy

**Task 1.5.3**: Create MVP demo script and cue card
- Duration: 30 minutes
- Write 3-minute demo video script showcasing:
  - Data aggregation system
  - Basic dashboard
  - Supply/demand tracking
  - Real-time updates
- Create cue card with narration and bullet points
- Highlight core MVP features

---

### Phase 2: Early Submission (Due Friday, November 7, 2025)

**Objective**: Add AI predictions, automated campaigns, and retention features

#### Phase 2.1: Supply/Demand Prediction System (180 minutes)

**Task 2.1.1**: Create prediction data model
- Duration: 30 minutes
- Design prediction schema
- Create `Prediction` model
- Store predictions and confidence scores
- Add database migrations

**Task 2.1.2**: Implement supply/demand predictor
- Duration: 90 minutes
- Create `SupplyDemandPredictor` Python model
- Use Prophet or LSTM for time-series forecasting
- Train model on historical supply/demand data
- Predict supply/demand for next 7-30 days
- Implement prediction API endpoint

**Task 2.1.3**: Integrate prediction into Rails
- Duration: 30 minutes
- Create `SupplyDemandPredictorService` in Rails
- Call Python ML service API
- Store predictions in database
- Schedule daily prediction job

**Task 2.1.4**: Build prediction UI
- Duration: 30 minutes
- Create `SupplyDemandPredictions` component
- Display predicted supply/demand
- Show prediction confidence intervals
- Visualize predictions vs actuals

#### Phase 2.2: Automated Campaign Adjustment System (150 minutes)

**Task 2.2.1**: Create campaign adjustment model
- Duration: 30 minutes
- Create `CampaignAdjustment` model
- Store campaign recommendations
- Add adjustment types (recruiting, incentives, pricing)
- Create database migrations

**Task 2.2.2**: Implement campaign adjuster service
- Duration: 60 minutes
- Create `CampaignAdjusterService` class
- Use AI to generate campaign recommendations:
  - When to recruit more tutors (subject, location)
  - What incentives to offer
  - How to adjust pricing
- Generate explainable recommendations

**Task 2.2.3**: Create campaign execution system
- Duration: 30 minutes
- Integrate with existing recruiting campaign API
- Execute campaign adjustments automatically
- Track campaign execution
- Store campaign results

**Task 2.2.4**: Build campaign UI
- Duration: 30 minutes
- Create `Campaigns` component
- Display campaign recommendations
- Show campaign execution status
- Track campaign effectiveness

#### Phase 2.3: Customer Health Score Dashboard (150 minutes)

**Task 2.3.1**: Implement customer health service
- Duration: 60 minutes
- Create `CustomerHealthService` class
- Calculate health scores based on:
  - First session success rates by tutor/subject
  - Session velocity trends by cohort
  - IB call frequency (≥2 calls in 14 days = churn risk)
  - Engagement metrics
- Store health scores in database

**Task 2.3.2**: Create customer health API
- Duration: 30 minutes
- Create customer health controller
- Implement endpoints for:
  - Get customer health scores
  - Get health trends
  - Get cohort comparisons
- Return structured health data

**Task 2.3.3**: Build customer health UI
- Duration: 60 minutes
- Create `CustomerHealth` component
- Display customer health scores
- Show first session success rates by tutor/subject
- Display session velocity trends by cohort
- Visualize health trends over time

#### Phase 2.4: Early Warning & Alert System (120 minutes)

**Task 2.4.1**: Implement IB call spike detection
- Duration: 30 minutes
- Create service to detect IB call spikes
- Identify customers with ≥2 calls in 14 days
- Calculate churn risk based on call frequency
- Store alerts in database

**Task 2.4.2**: Implement churn prediction by segment
- Duration: 45 minutes
- Create `ChurnPredictorService` (Python)
- Build ML model for churn prediction
- Segment customers by attributes
- Predict churn risk by segment
- Return risk scores

**Task 2.4.3**: Create early warning alert service
- Duration: 30 minutes
- Create `EarlyWarningService` class
- Generate alerts for at-risk customers
- Integrate with notification system
- Send alerts to operators
- Track alert responses

**Task 2.4.4**: Build alerts UI
- Duration: 15 minutes
- Create `Alerts` component
- Display early warning alerts
- Show churn risk indicators
- Display IB call spike alerts
- Add alert management

#### Phase 2.5: Anomaly Detection (120 minutes)

**Task 2.5.1**: Implement anomaly detector
- Duration: 60 minutes
- Create `AnomalyDetector` Python model
- Use Isolation Forest or LSTM Autoencoder
- Detect anomalies in:
  - Session patterns
  - Booking patterns
  - Supply/demand patterns
  - Performance metrics
- Return anomaly scores

**Task 2.5.2**: Integrate anomaly detection
- Duration: 30 minutes
- Integrate Python model into Rails
- Schedule anomaly detection job
- Store anomalies in database
- Generate alerts for anomalies

**Task 2.5.3**: Build anomaly UI
- Duration: 30 minutes
- Create `Anomalies` component
- Display detected anomalies
- Show anomaly details and context
- Visualize anomaly patterns
- Add anomaly investigation tools

#### Phase 2.6: Unit Testing & Integration Testing (90 minutes)

**Task 2.6.1**: Write unit tests for prediction system
- Duration: 30 minutes
- Test supply/demand prediction
- Test prediction service integration
- Test prediction accuracy

**Task 2.6.2**: Write unit tests for campaign system
- Duration: 30 minutes
- Test campaign adjustment generation
- Test campaign execution
- Test campaign tracking

**Task 2.6.3**: Write integration tests for retention features
- Duration: 30 minutes
- Test customer health calculation
- Test early warning alerts
- Test anomaly detection
- Test end-to-end retention flow

#### Phase 2.7: Early Submission Demo Script & Cue Card (60 minutes)

**Task 2.7.1**: Create early submission demo script
- Duration: 30 minutes
- Write 3-minute demo video script showcasing:
  - Supply/demand predictions
  - Automated campaign adjustments
  - Customer health dashboard
  - Early warning alerts
  - Anomaly detection
  - Retention features working together
- Create cue card with narration and bullet points
- Highlight retention enhancement features

**Task 2.7.2**: Prepare demo environment
- Duration: 30 minutes
- Set up test data for demo
- Prepare sample scenarios
- Verify all features work for recording

---

### Phase 3: Final Submission (Due Sunday, November 9, 2025)

**Objective**: Full analytics, explainable AI, and production readiness

#### Phase 3.1: Explainable AI Recommendations (180 minutes)

**Task 3.1.1**: Implement explainable recommendation service
- Duration: 60 minutes
- Create `ExplainableRecommendationService` class
- Use OpenAI to generate explainable recommendations
- Explain why each recommendation is made
- Provide supporting data and context
- Store explanations in database

**Task 3.1.2**: Build explanation UI
- Duration: 60 minutes
- Create `ExplainableRecommendations` component
- Display recommendations with explanations
- Show supporting data and metrics
- Visualize recommendation reasoning
- Add interactive exploration

**Task 3.1.3**: Integrate explanations into all predictions
- Duration: 30 minutes
- Add explanations to supply/demand predictions
- Add explanations to campaign recommendations
- Add explanations to churn predictions
- Add explanations to anomaly alerts

**Task 3.1.4**: Create explanation documentation
- Duration: 30 minutes
- Document explanation format
- Explain explanation generation process
- Provide examples of good explanations
- Create explanation quality guidelines

#### Phase 3.2: Advanced Analytics Dashboard (150 minutes)

**Task 3.2.1**: Create advanced analytics service
- Duration: 45 minutes
- Create `AdvancedAnalyticsService` class
- Calculate advanced metrics:
  - Cohort analysis
  - Trend analysis
  - Correlation analysis
  - Predictive analytics
- Aggregate data efficiently

**Task 3.2.2**: Build advanced analytics API
- Duration: 45 minutes
- Create advanced analytics controller
- Implement endpoints for:
  - Cohort analytics
  - Trend analysis
  - Correlation metrics
  - Predictive insights
- Add caching for performance

**Task 3.2.3**: Create advanced analytics UI
- Duration: 60 minutes
- Build `AdvancedAnalytics` component
- Display cohort comparisons
- Show trend analysis charts
- Visualize correlations
- Add interactive filters and drill-downs

#### Phase 3.3: Real-time Data Processing Optimization (120 minutes)

**Task 3.3.1**: Optimize for 50+ data streams
- Duration: 45 minutes
- Implement efficient data aggregation
- Add batch processing for large datasets
- Optimize database queries
- Implement caching strategies
- Ensure real-time processing

**Task 3.3.2**: Implement real-time WebSocket updates
- Duration: 30 minutes
- Optimize Action Cable for real-time updates
- Implement efficient data broadcasting
- Add connection management
- Handle connection failures gracefully

**Task 3.3.3**: Add performance monitoring
- Duration: 30 minutes
- Monitor data processing latency
- Track API response times
- Monitor WebSocket performance
- Add performance dashboards
- Alert on performance issues

**Task 3.3.4**: Optimize ML model performance
- Duration: 15 minutes
- Optimize prediction model inference time
- Cache model predictions
- Batch prediction requests
- Monitor ML service performance

#### Phase 3.4: Production Hardening (120 minutes)

**Task 3.4.1**: Add error handling and logging
- Duration: 30 minutes
- Implement comprehensive error handling
- Add logging for all data streams
- Log all AI API calls
- Setup error monitoring (Sentry)

**Task 3.4.2**: Implement rate limiting and caching
- Duration: 30 minutes
- Add rate limiting for API endpoints
- Implement Redis caching for predictions
- Cache dashboard data
- Optimize cache invalidation

**Task 3.4.3**: Add security and access control
- Duration: 30 minutes
- Implement role-based access control
- Secure API endpoints
- Add authentication for ML service
- Audit log access

**Task 3.4.4**: Performance optimization
- Duration: 30 minutes
- Optimize database queries
- Add missing indexes
- Implement pagination
- Add query optimization monitoring

#### Phase 3.5: Documentation & Deployment (120 minutes)

**Task 3.5.1**: Write AI prompting strategies documentation
- Duration: 30 minutes
- Document all AI prompts used
- Explain prompting strategies for recommendations
- Document explainable AI prompts
- Include examples

**Task 3.5.2**: Create ML model documentation
- Duration: 30 minutes
- Document supply/demand prediction model
- Document churn prediction model
- Document anomaly detection model
- Explain feature engineering

**Task 3.5.3**: Create integration guide
- Duration: 30 minutes
- Document Rails/React integration
- Document Python ML service integration
- Document 50+ data stream integrations
- Include troubleshooting guide

**Task 3.5.4**: Deploy to cloud (AWS or Vercel)
- Duration: 30 minutes
- Deploy backend to AWS (or Heroku/Railway)
- Deploy Python ML service
- Deploy frontend to Vercel
- Configure environment variables
- Verify deployment works

#### Phase 3.6: Comprehensive Testing (90 minutes)

**Task 3.6.1**: Write end-to-end tests
- Duration: 30 minutes
- Test complete data aggregation flow
- Test prediction generation flow
- Test alert generation flow
- Test campaign adjustment flow

**Task 3.6.2**: Write unit tests for all services
- Duration: 30 minutes
- Test all data aggregation services
- Test prediction services
- Test automation services
- Achieve >80% code coverage

**Task 3.6.3**: Performance testing
- Duration: 30 minutes
- Test 50+ data stream processing
- Test real-time update performance
- Test API response times
- Verify system handles expected load

#### Phase 3.7: Cost Analysis & Final Demo (90 minutes)

**Task 3.7.1**: Create cost analysis document
- Duration: 30 minutes
- Analyze OpenAI API costs
- Estimate ML service hosting costs
- Estimate TimescaleDB costs
- Document cost optimization strategies
- Create cost projection for production

**Task 3.7.2**: Create final demo video script and cue card
- Duration: 30 minutes
- Write 3-minute demo video script showcasing:
  - Complete dashboard with 50+ data streams
  - Supply/demand predictions
  - Automated campaign adjustments
  - Customer health dashboard
  - Explainable AI recommendations
  - Early warning alerts
  - Anomaly detection
- Create cue card with narration and bullet points
- Highlight production-ready features

**Task 3.7.3**: Final system walkthrough
- Duration: 30 minutes
- Verify all features work end-to-end
- Test with 50+ data streams
- Verify real-time updates
- Verify explainable AI working
- Prepare demo environment

---

## Success Metrics

### Technical Metrics
- ✅ Process 50+ data streams in real-time
- ✅ Dashboard update latency < 5 seconds
- ✅ System uptime > 99%
- ✅ API response time < 500ms (95th percentile)
- ✅ ML model prediction accuracy > 85%

### Business Metrics
- ✅ Identify at-risk customers through early warning alerts
- ✅ Optimize tutor supply through demand prediction
- ✅ Improve first session success rates through insights
- ✅ Reduce operational overhead through automation
- ✅ Generate explainable recommendations for 100% of predictions

### Operational Metrics
- ✅ Supply/demand prediction accuracy > 90%
- ✅ Churn prediction precision > 80%
- ✅ Campaign adjustment effectiveness > 70%
- ✅ Anomaly detection recall > 85%

---

## Risk Assessment & Mitigation

### Risk 1: Processing 50+ Data Streams
- **Probability**: Medium
- **Impact**: High
- **Mitigation**: Implement efficient aggregation, batch processing, caching, horizontal scaling

### Risk 2: Real-time Update Performance
- **Probability**: Medium
- **Impact**: Medium
- **Mitigation**: Optimize WebSocket connections, implement efficient broadcasting, add connection pooling

### Risk 3: ML Model Accuracy
- **Probability**: Medium
- **Impact**: High
- **Mitigation**: Iterative model training, feature engineering, validation against historical data

### Risk 4: Explainable AI Quality
- **Probability**: Medium
- **Impact**: Medium
- **Mitigation**: Iterative prompt engineering, user feedback loop, A/B testing explanations

---

## Dependencies

### External Dependencies
- OpenAI API access and credits
- Existing Nerdy Rails/React platform access
- 50+ data stream APIs access
- PostgreSQL with TimescaleDB access
- Python ML service hosting

### Internal Dependencies
- Design system components
- Authentication system
- Notification system
- WebSocket infrastructure
- Campaign management API

---

## Appendix: AI Prompting Strategies

### Explainable Recommendation Prompt Template
```
Based on this marketplace data, provide a recommendation with explanation:
- Current state: [CURRENT_STATE]
- Prediction: [PREDICTION]
- Historical context: [HISTORY]

Provide:
1. Recommendation (specific action)
2. Explanation (why this recommendation)
3. Supporting data (metrics, trends)
4. Expected outcome (what will happen)
5. Confidence level (how certain)

Format: Clear, actionable, explainable.
```

### Campaign Adjustment Prompt Template
```
Supply/demand imbalance detected:
- Subject: [SUBJECT]
- Supply: [SUPPLY]
- Demand: [DEMAND]
- Gap: [GAP]

Generate campaign adjustment recommendation:
- When to recruit (specific timing)
- Where to recruit (location/subject)
- What incentives to offer
- Expected results

Provide explainable reasoning for each recommendation.
```

### Churn Prediction Explanation Prompt Template
```
Customer churn risk score: [RISK_SCORE]
Customer segment: [SEGMENT]
Key indicators:
- First session: [FIRST_SESSION]
- IB calls: [IB_CALLS]
- Session velocity: [VELOCITY]

Explain:
1. Why this customer is at risk
2. Key contributing factors
3. Recommended interventions
4. Expected outcomes

Format: Clear, actionable, explainable.
```

---

*Document Version: 1.0*  
*Created: November 3, 2025*  
*Last Updated: November 3, 2025*  
*Status: Ready for Execution*

```

All three PRDs are complete. Updating the TODO list:


Created three PRDs for the Nerdy Case 5 options:

## Created PRDs

1. **PRD-Nerdy-OptionA-AI-Study-Companion.md** — AI Study Companion with session memory, adaptive practice, and retention features
2. **PRD-Nerdy-OptionB-Tutor-Quality-Scoring.md** — Tutor Quality Scoring System processing 3,000 sessions/day with churn prediction
3. **PRD-Nerdy-OptionC-Intelligent-Operations-Dashboard.md** — Intelligent Operations Dashboard handling 50+ data streams with explainable AI

## Each PRD includes

- Executive Summary with business impact
- Project Timeline aligned to your dates:
  - Phase 1 (MVP): Tuesday, November 4, 2025
  - Early Submission: Friday, November 7, 2025
  - Final Submission: Sunday, November 9, 2025
- Technology Stack (Rails/React integration, AI/ML services)
- Architecture Overview with system components
- Phase Breakdown with granular tasks (15–90 minutes each)
- Integrated Unit Testing as the final task in each phase
- Demo Video Script (3 minutes) and Cue Card for due date phases
- Success Metrics, Risk Assessment, and Dependencies
- AI Prompting Strategies appendix

All PRDs follow the October 16, 2025 success path methodology and are ready for execution. Each includes phased planning with specific time estimates and deliverables.

Note: When we begin execution, I will wait for your confirmation before proceeding to the next task, and all terminal commands will use PowerShell syntax.

Ready to proceed with execution once you choose which option to pursue.

